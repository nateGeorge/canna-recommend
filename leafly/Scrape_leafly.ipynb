{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import cPickle as pk\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import threading\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from scrape_leafly import scrape_strainlist\n",
    "\n",
    "DB_NAME = \"leafly\"\n",
    "COLLECTION_NAME = \"reviews\"\n",
    "\n",
    "client = MongoClient()\n",
    "db = client[DB_NAME]\n",
    "coll = db[COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strain_page_file = 'leafly_strains_page.pk'\n",
    "base_url = 'https://www.leafly.com'\n",
    "strain_url = base_url + '/explore/sort-alpha'\n",
    "\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.set_window_size(1920, 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists(strain_page_file):\n",
    "    strain_page = pk.load(open(strain_page_file))\n",
    "    strain_soup = bs(strain_page, 'lxml')\n",
    "else:\n",
    "    strain_soup = scrape_strainlist(strain_page_file)\n",
    "\n",
    "# get list of strain pages\n",
    "strains = strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'}) + strain_soup.findAll('a', {'class': 'ng-scope'})\n",
    "strains = [s.get('href') for s in strains]\n",
    "    \n",
    "strain_pages_file = 'strain_pages_list.pk'\n",
    "if not os.path.exists(strain_pages_file):\n",
    "    pk.dump(strains, open(strain_pages_file, 'w'), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_if_strains_uptodate():\n",
    "    '''\n",
    "    scrapes leafly main page to check if any new strains have been added\n",
    "    '''\n",
    "    strain_len = len(strains)\n",
    "    print 'currently have', strain_len, 'strains'\n",
    "    driver.get(strain_url)\n",
    "    alpha_sort_soup = bs(driver.page_source, 'lxml')\n",
    "    cur_strains = int(alpha_sort_soup.findAll('strong', {'class':'ng-binding'})[0].get_text())\n",
    "    print 'found', cur_strains, 'strains on leafly'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently have 2122 strains\n",
      "found 2115 strains on leafly\n"
     ]
    }
   ],
   "source": [
    "check_if_strains_uptodate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hybrid/100-og'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'})[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.leafly.com/hybrid/100-og'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url + strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'})[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_page = base_url + strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'})[0].get('href') + '/reviews?page=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.get(reviews_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = bs(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.leafly.com/hybrid/100-og/reviews?page=0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = soup.findAll('li', {'class': 'page-item divider bottom padding-listItem'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'TrippyLama'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0].findAll('a', {'class': 'no-color'})[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0].findAll('span', {'class': 'squeeze ng-isolate-scope'})[0].get('star-rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I like the high makes me feel motivation'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0].findAll('p', {'class': 'copy--xs copy-md--md'})[0].get_text()[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-10-03 23:48:46Z'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0].findAll('time', {'class': 'copy--xs copy-md--sm timestamp pull-right hidden-xs hidden-sm'})[0].get('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(soup.findAll('span', {'class': 'hidden-xs'})[0].get_text().strip('(').strip(')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_reviews_page(url, verbose=True):\n",
    "    '''\n",
    "    scrapes reviews page for all reviews\n",
    "    url is a string for the specified strain homepage\n",
    "    \n",
    "    returns list of reviews\n",
    "    each review consist of a tuple of (user, stars, review_text, datetime_of_review)\n",
    "    '''\n",
    "    # num photos is index 1\n",
    "    num_reviews = int(soup.findAll('span', {'class': 'hidden-xs'})[0].get_text().strip('(').strip(')'))\n",
    "    print num_reviews, 'total reviews to scrape'\n",
    "    reviews = []\n",
    "    i = 0\n",
    "    while len(reviews) < num_reviews:\n",
    "        cur_url = url + '/reviews?page=' + str(i)\n",
    "        if verbose:\n",
    "            print 'scraping', cur_url\n",
    "        i += 1\n",
    "        driver.get(cur_url)\n",
    "        rev_soup = bs(driver.page_source, 'lxml')\n",
    "        reviews_soup = rev_soup.findAll('li', {'class': 'page-item divider bottom padding-listItem'})\n",
    "        if verbose:\n",
    "            print len(reviews_soup), 'reviews on page'\n",
    "        for r in reviews_soup:\n",
    "            user = r.findAll('a', {'class': 'no-color'})[0].get_text()\n",
    "            stars = r.findAll('span', {'class': 'squeeze ng-isolate-scope'})[0].get('star-rating')\n",
    "            text = r.findAll('p', {'class': 'copy--xs copy-md--md'})[0].get_text()[1:-1]\n",
    "            date = r.findAll('time', \\\n",
    "                             {'class': \\\n",
    "                              'copy--xs copy-md--sm timestamp pull-right hidden-xs hidden-sm'}) \\\n",
    "                                [0].get('datetime')\n",
    "            reviews.append((user, stars, text, date))\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_a_review_page(url, verbose=True):\n",
    "    '''\n",
    "    scrapes review page and puts all the info in a mongodb, because it is unordered\n",
    "    '''\n",
    "    res = requests.get(url)\n",
    "    rev_soup = bs(res.content, 'lxml')\n",
    "    reviews_soup = rev_soup.findAll('li', {'class': 'page-item divider bottom padding-listItem'})\n",
    "    if verbose:\n",
    "        print len(reviews_soup), 'reviews on page'\n",
    "    for r in reviews_soup:\n",
    "        user = r.findAll('a', {'class': 'no-color'})[0].get_text()\n",
    "        stars = r.findAll('span', {'class': 'squeeze'})[0].get('star-rating')\n",
    "        text = r.findAll('p', {'class': 'copy--xs copy-md--md'})[0].get_text()[1:-1]\n",
    "        date = r.findAll('time', \\\n",
    "                         {'class': \\\n",
    "                          'copy--xs copy-md--sm timestamp pull-right hidden-xs hidden-sm'}) \\\n",
    "                            [0].get('datetime')\n",
    "        \n",
    "        datadict = {}\n",
    "        datadict['user'] = user\n",
    "        datadict['stars'] = stars\n",
    "        datadict['text'] = text\n",
    "        datadict['date'] = date\n",
    "        coll.insert_one(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_reviews = int(soup.findAll('span', {'class': 'hidden-xs'})[0].get_text().strip('(').strip(')'))\n",
    "num_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_reviews/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_reviews_page_threads(url, genetics, verbose=True):\n",
    "    '''\n",
    "    scrapes reviews page for all reviews\n",
    "    url is a string for the specified strain homepage\n",
    "    \n",
    "    returns list of reviews\n",
    "    each review consist of a tuple of (user, stars, review_text, datetime_of_review)\n",
    "    '''\n",
    "    # num photos is index 1\n",
    "    num_reviews = int(soup.findAll('span', {'class': 'hidden-xs'})[0].get_text().strip('(').strip(')'))\n",
    "    print num_reviews, 'total reviews to scrape'\n",
    "    pages = num_reviews / 8\n",
    "    scrapetime = datetime.utcnow().isoformat()\n",
    "    threads = []\n",
    "    if coll.find({'genetics': genetics}).count() < 1:\n",
    "        coll.insert_one({'genetics': genetics})\n",
    "    if coll.find({'name': 'scrape_datetime'}).count() < 1:\n",
    "        coll.insert_one({'scrape_times': scrapetime})\n",
    "        coll.insert_one({'review_count': num_reviews})\n",
    "    else:\n",
    "        coll.update_one({'scrape_times': {'$exists': true}}, {'$push': {'scrape_times': scrapetime}})\n",
    "        coll.update_one({'review_count': {'$exists': true}}, {'$push': {'review_count': num_reviews}})\n",
    "    if coll.find({'review_count':{'$exists':'true'}}).next()['review_count'] == num_reviews:\n",
    "        print 'already up-to-date'\n",
    "        return\n",
    "    for i in range(pages + 1):\n",
    "        cur_url = url + '/reviews?page=' + str(i)\n",
    "        if verbose:\n",
    "            print 'scraping', cur_url\n",
    "        #scrape_a_review_page(cur_url)\n",
    "        t = threading.Thread(target=scrape_a_review_page, args=(cur_url,))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for th in threads:\n",
    "        th.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.find({'genetics': genetics}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coll = db[strain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'leafly'), u'100-og')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.find({'genetics': genetics}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_page_100og = base_url + strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'})[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genetics = strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'})[0].get('href').split('/')[1]\n",
    "strain = strain_soup.findAll('a', {'class': 'ga_Explore_Strain_Tile'})[0].get('href').split('/')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.find({'review_count':{'$exists':'true'}}).next()['review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 total reviews to scrape\n",
      "already up-to-date\n"
     ]
    }
   ],
   "source": [
    "coll = db[strain]\n",
    "scrape_reviews_page_threads(reviews_page_100og, genetics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/14184099/fastest-way-to-remove-duplicate-documents-in-mongodb\n",
    "# will drop dupe reviews in mongo:\n",
    "#db['100-og'].ensureIndex({text: 1}, {unique: true, dropDups: true}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scrapes synchronously...very slow\n",
    "print 'scraping', reviews_page_100og\n",
    "reviews_list = scrape_reviews_page(reviews_page_100og)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
